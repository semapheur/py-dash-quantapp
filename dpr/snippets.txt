888b     d888                                8888888b. 888888b.   
8888b   d8888                                888  "Y88b888  "88b  
88888b.d88888                                888    888888  .88P  
888Y88888P888 .d88b. 88888b.  .d88b.  .d88b. 888    8888888888K.  
888 Y888P 888d88""88b888 "88bd88P"88bd88""88b888    888888  "Y88b 
888  Y8P  888888  888888  888888  888888  888888    888888    888 
888   "   888Y88..88P888  888Y88b 888Y88..88P888  .d88P888   d88P 
888       888 "Y88P" 888  888 "Y88888 "Y88P" 8888888P" 8888888P"  
                                  888                             
                             Y8b d88P                             
                              "Y88P"                                                 
                                                              
** Connect
client = MongoClient('mongodb://localhost:27017/')
coll = client['db']['coll']

** Remove all null/nan fields
pipeline = [{
    '$replaceWith': {
        '$arrayToObject': {
            '$filter': {
                'input': { '$objectToArray': "$$ROOT" },
                'as': "item",
                'cond': { '$ne': ["$$item.v", np.nan] }
            }
        }
    }
}]
coll.update_many({}, pipeline)

** Replace fields containing .
pipeline = [
    {'$addFields': {
        'ticker.barrons': {'$getField': "ticker.barrons"},
        'ticker.investing': {'$getField': "ticker.investing"},
        'ticker.trim': {'$getField': "ticker.trim"},
        'exchange.mic': {'$getField': "exchange.mic"},
        'exchange.morningstarMic': {'$getField': "exchange.morningstarMic"},
        'link.barrons': {'$getField': "link.barrons"},
        'link.investing': {'$getField': "link.investing"}
        }
    },
    {'$replaceWith': {
        '$arrayToObject': {
            '$filter': {
                'input': { '$objectToArray': "$$ROOT" },
                'as': "item",
                'cond': { '$ne': ["$$item.v", None] }
                }
            }
        }
    },
    {'$replaceWith': {
        '$arrayToObject': {
            '$filter': {
                'input': { '$objectToArray': "$$ROOT" },
                'as': "item",
                'cond': { '$eq': [{'$indexOfBytes': ["$$item.k", "."]}, -1]}
                }
            }
        }
    }
]

** Replace substring
query = {'ticker.trim': {'$regex': '-'}}

updt = [{
    '$set': {
        'ticker.trim': {
            '$replaceAll': {
                'input': {'$toLower': '$ticker.trim'},
                'find': '-',
                'replacement': ''
            }
        }
    }
}]

coll.update_many({}, pipeline)

** Delete duplicate documents
query = {
    '$match': {
        '$and': [
            {'id.morningstar': {'$exists': False}},
            {'link.investing': {'$exists': True}}
        ]
    }
}
    
pipeline = [
    query,
    {'$group': {
        '_id': '$link.investing', 
        'uniqueIds': {'$addToSet': '$_id'},
        'count': {'$sum': 1}
        }
    },
    {'$match': {
        'count': {'$gte': 2}
        }
    }
]

cursor = coll.aggregate(pipeline)
resp = []

for doc in cursor:
    del doc['uniqueIds'][0]
    resp.extend(doc['uniqueIds'])

coll.delete_many({'_id': {'$in': resp}})

** Merge documents
query = {
    '$match': {
        '$and': [
            {'type': 'stock'},
            {'$or': [
                {'$and': [
                    {'id.morningstar': {'$exists': True}},
                    {'link.barrons': {'$exists': False}}
                ]},
                {'$and': [
                    {'id.morningstar': {'$exists': False}},
                    {'link.barrons': {'$exists': True}}
                ]}
            ]}
        ]
    }
}

pipeline = [
    query,
    {'$group': {
        '_id': {
            'ticker': '$ticker.trim',
            'exchange': '$exchange.morningstarMic'
        }, 
        'uniqueIds': {'$addToSet': '$_id'},
        'count': {'$sum': 1}
        }
    },
    {'$match': {
        'count': {'$gte': 2}
        }
    },
]

cursor = coll.aggregate(pipeline)

delId = []
records = []
for doc in cursor:
    ids = doc['uniqueIds']
    delId.extend(ids)
    
    pipeline = [
        {'$match': {'_id': {'$in': ids}}},
        {'$group': {
            '_id': '$ticker.trim',
            'type': {'$first': '$type'},
            'id': {'$mergeObjects': '$id'}, 
            'ticker': {'$mergeObjects': '$ticker'},
            'name': {'$first': '$name'},
            'sector': {'$first': '$sector'},
            'industry': {'$first': '$industry'},
            'exchange': {'$mergeObjects': '$exchange'},
            'link': {'$mergeObjects': '$link'},
            }
        },
        {'$project': {'_id': 0}},
        #{'$out': {'db': 'test', 'coll': 'result'}}
    ]
    records.extend(list(coll.aggregate(pipeline)))
    
coll.insert_many(records)
coll.delete_many({'_id': {'$in': delId}})


 .d8888b.  .d88888b. 888      
d88P  Y88bd88P" "Y88b888      
Y88b.     888     888888      
 "Y888b.  888     888888      
    "Y88b.888     888888      
      "888888 Y8b 888888      
Y88b  d88PY88b.Y8b88P888      
 "Y8888P"  "Y888888" 88888888 
                 Y8b        

** Query
SELECT DISTINCT field1, field2
FROM tbl1, tbl2
WHERE col1 IN (val1, val2) OR NOT col2 = val3 AND rowid > 10
ORDER BY col1

DROP TABLE tbl1 IF EXISTS

** Full outer join
query = textwrap.dedent('''
    SELECT morningstarId, ms.ticker AS morningstarTicker, ms.tickerTrim AS trim, 
        ms.name AS morningstarName, ms.morningstarMic AS morningstarMic,
        brn.ticker AS barronsTicker, brn.name AS barronsName,
        inv.ticker AS investingTicker, inv.name AS investingName,
        yho.ticker AS yahooTicker, yho.name AS yahooName
    FROM morningstarStock AS ms
    
    JOIN exchange AS e 
        ON brn.exchange = e.morningstarMic
        AND inv.exchange = e.morningstarMic
        AND yho.exchange = e.morningstarMic
    
    FULL OUTER JOIN barronsStock AS brn
        ON trim = brn.tickerTrim AND ms.morningstarMic = brn.exchange
        AND (trim = inv.tickerTrim AND ms.morningstarMic = inv.exchange)
        AND (trim = yho.tickerTrim AND ms.morningstarMic = yho.exchange)
''')

** Full outer join emulation
tbl = f'{src}{asset.capitalize()}'
query = textwrap.dedent(f'''
    SELECT morningstarId, ms.ticker AS morningstarTicker, ms.tickerTrim AS tickerTrim, 
        ms.name AS morningstarName, ms.morningstarMic AS morningstarMic,
        {tbl}.ticker AS {src}Ticker, {tbl}.name AS {src}Name
    FROM morningstarStock AS ms
    JOIN exchange AS e ON {tbl}.exchange = e.morningstarMic
    LEFT OUTER JOIN {tbl}
    ON morningstarTicker = {tbl}.tickerTrim 
        AND ms.morningstarMic = {tbl}.exchange
    UNION ALL
    SELECT morningstarId, ms.ticker AS morningstarTicker, ms.tickerTrim AS tickerTrim, 
        ms.name AS morningstarName, ms.morningstarMic AS morningstarMic,
        {tbl}.ticker AS {src}Ticker, {tbl}.name AS {src}Name
    FROM {tbl}
    JOIN exchange AS e ON {tbl}.exchange = e.morningstarMic
    LEFT OUTER JOIN morningstarStock AS ms
    ON morningstarTicker = {tbl}.tickerTrim 
        AND ms.morningstarMic = {tbl}.exchange
    WHERE  morningstarTicker IS NULL
''')

** SQLite string split
xchgSplit = textwrap.dedent(f'''
    WITH split(xch, str) AS (
        SELECT '', e.{src}Exchange||'/' FROM e
            WHERE e.{src}Exchange IS NOT NULL
        UNION ALL SELECT
        xid,
        substr(str, 0, instr(str, "/")),
        substr(str, instr(str, "/")+1)
        FROM split WHERE str != ""
    ) SELECT xchg FROM split WHERE xchg != ''
''')

** SQLAlchemy
engine = sqla.create_engine('sqlite:///db.sqlite')
connection = engine.connect()
metadata = db.MetaData()
tbl = db.Table('tbl', metadata, autoload=True, autoload_with=engine)

* Execute queries
with engine.connect() as connection:
    with connection.begin():
            connection.execute(query)

* Select where
query = db.select([tbl1.columns.col1.distinct(), tbl1.columns.col2]).where(tbl1.columns.state.in_([val1, val2]))
result = connection.execute(query).fetchall()

* Join
query = db.select([tbl1, tbl2])
query = query.select_from(tbl1.join(tbl2, tbl1.columns.col1 == tbl2.columns.col2))
results = connection.execute(query).fetchall()

* Drop table
tbl.drop(engine)